Cross-validation is a technique used in machine learning and statistics to evaluate the generalization ability of an algorithm or model. It involves dividing a larger dataset into two subsets, one for training (i.e., validation) and another for testing (i.e., prediction). The training set is used to fit the model or estimate its parameters, while the test set is used to assess how well it performs on unseen data. Cross-validation helps to identify which parts of the dataset are most relevant for generalization and can help fine-tune the model's parameters for better performance.