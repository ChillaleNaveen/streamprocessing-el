Gradient descent is an optimization algorithm that finds local minima (i.e., points with the lowest value of a function) by repeatedly applying small steps in the opposite direction of the gradient, which points to the direction of steepest ascent. The algorithm proceeds until convergence is reached or a maximum number of iterations are performed. Gradient descent works by iteratively adjusting each variable based on its current value and its gradient (a measure of its difference from a local minumum). The direction of the gradient descent step is determined based on the magnitude of the gradient, which helps to minimize the function's curvature.